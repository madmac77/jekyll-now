Week 2: Project 2- Billboard Data Analysis

This project conducts an analysis of the top songs from the year 2000 and looks to find statistical relationships and patterns in various data attributes.

1. Load/identify data file 
2. Clean data
3. Explore data / Question/ Hypothesis
4. Conduct analyses
5. Present results 


1. Load/Identify data file 

The data file has 317 rows and 83 columns of data.  Several columns of data are strings, others numeric.  Much of the data that will undergo analysis needs to be cleansed- blank entries have '*', not Null values. 

df.info shows us that several columns need to be cleansed as they are type non-null object. 

![Violin](madmac77.github.io/images/billboard_1)



2. Clean Data

![Violin](madmac77.github.io/images/billboard_2)


'Time' column is length of song and needed to be cleaned and converted. 

![Violin](madmac77.github.io/images/billboard_5)

All columns that indicated the rank of a song in the top 100 had to be converted from object to numeric. 

![Violin](madmac77.github.io/images/billboard_3)

The columns representing the later weeks on the charts (ranging from week 1 to week 76) had to be converted from non-null object to numeric as well as replace the * characters. I did this with a .to_numeric and coerce. 

![Violin](madmac77.github.io/images/billboard_6)


I added two new columns representing the Max Score (the value of the songs peak on the Billboard Top 100) and Min Score for each song.


Also cleaned the names of the columns.
![Violin](madmac77.github.io/images/billboard_10)

3. Data Exploration/ Question/Hypothesis


I saw two columns - Date Entered and Date Peaked and realized that the difference would provide a useful metric to examine- the time it took to Peak (Time to Peak).  

![Violin](madmac77.github.io/images/billboard_7)

![Violin](madmac77.github.io/images/billboard_8)


As I used pandas to calculate the differnce and insert into the Dataframe as a new column, Time to Peak, I realized that the output of the difference was presented in a TimeStamp format (Timestamp('2000-02-12 00:00:00').  The issue with this was only realized later as I tried to run analyses between this column and other numeric columns. TimeDelta error kept occuring and I realized that I had to further clean the Time to Peak column.  After several frustrating hours, I converted it in a simple but effective manner to Integers using .split/.append methods. 

![Violin](madmac77.github.io/images/billboard_9)


The 'score' of a song in any week (between weeks 1-76 in the dataset) was out of 100, but presented with 1 being the highest, which is a bit misleading. I was going to convert them into a max score of 100 (ie 1 would become 100) but decided that I'd rather do a comparison of the lenght of time on the charts, for which the absolute ranking in a given week was irrelevant.  In particular I wanted to compare the Time to Peak with this number of weeks in the top 100.  In order to accomplish this I had to count the columns for which a song had a value (1-100), and ignore the NaN values.  I cleaned the data by dividing each number by itself to convert every song score into '1' and also replaced the NaNs with '0'.  I then simply took a sum of the columns (which were either 1 or 0) to get a new column, Time on Charts. 
![Violin](madmac77.github.io/images/billboard_13)

![Violin](madmac77.github.io/images/billboard_15)

![Violin](madmac77.github.io/images/billboard_16)


Now that I had my data converted and in a position to examine thoroughly I came up with the following questions:

1) Is the data distributed normally?  I picked several variables and examined them using histograms and basic stats. 
2) Can Time to Peak accurately predict Time on Charts?  Regression analysis between Time to Peak and Time on Charts. 

Hypothesis:
1) Null Hypothesis for Time variable is that the difference between my sample Time variable mean and an infinite universe of Top 100 Billboard songs mean Time is zero. 


4. Conduct Analyses

I looked at several variables and examined their plots (histograms and distplots) to see their count and distribution.  Perhaps unsurprisingly there didn't seem to be a normal distribution across variables. 

Interesting histogram- not all songs LEAVE the top 100 in the lower echelons before disappearing off the top100,some songs fade quickly.
![Violin](madmac77.github.io/images/minrank)



For the purposes of this Project I focused on the distribution of the Time variable.  Recall the Null Hypothesis is that there was no difference between the sample mean and universe when, using a significance level of 0.05. 

![Violin](madmac77.github.io/images/time_describe)

![Violin](madmac77.github.io/images/time_hist)

![Violin](madmac77.github.io/images/time_hist2)

![Violin](madmac77.github.io/images/time_dist4)

In this sample set, Time had a mean of just over 4 minutes (242 seconds).  Using stats.ttest, the t-statistic is -0.002 and the p-value is 0.999. As 0.999> 0.05, we fail to reject the Null Hypothesis.
  

I also wanted to explore the relationship between Time to Peak and Time on Charts.  

![Violin](madmac77.github.io/images/time_peakhist)

![Violin](madmac77.github.io/images/timepeak_dist)

![Violin](madmac77.github.io/images/timecharthist)

![Violin](madmac77.github.io/images/time_chartdist)

Plot the two variables with Seaborn:
![Violin](madmac77.github.io/images/peakvchart)

![Violin](madmac77.github.io/images/timepeakvchart2)

Correlation Analysis:
![Violin](madmac77.github.io/images/time_corr)

High score suggest strong relationship between the two, not unexpected given that Time on Charts and Time to Peak are inherently related, which could also suggest that the 'model' is less useful than intended. 


Regression Model (OLS):
![Violin](madmac77.github.io/images/time_regress)

y= 6.76 + 0.19x
time_on_charts= 6.76 + 0.19(time_to_peak)

Created new Dataframe with the various expected outputs, mean, MSE etc to plot the resulting model and residuals:

Plot Model vs Expected:

![Violin](madmac77.github.io/images/model_true)
Plot Residuals:

![Violin](madmac77.github.io/images/resids_true)



